# dataset statistics

## overview

This research analyzed a comprehensive dataset of conversations between Benjamin, an autistic individual, and Claude, an AI assistant. The dataset provides a unique window into the interaction patterns that emerge when neurodivergent cognitive processing meets contemporary AI design.

### core dataset metrics

- **total conversations:** 255
- **total messages:** 5,338
- **user messages analyzed:** 2,672
- **claude responses analyzed:** 2,666
- **data volume:** 89.5mb
- **time period:** 26 days
- **average conversation length:** 20.9 messages
- **longest conversation:** 294 messages (first chat with claude)

The dataset represents real-world interactions across a diverse range of tasks, from technical troubleshooting to legal complaint drafting to decision-making support. This breadth provides robust evidence for pattern detection across multiple contexts.

## cycle prevalence

The analysis identified four pathological vicious cycles, one natural trait pattern, and rejected two hypothesized cycles based on evidence.

### pathological cycles

| cycle | conversations | percentage | severity | completion rate |
|-------|--------------|------------|----------|----------------|
| cycle 4: emotional dysregulation | 129 | 50.6% | 33% severe | 0% baseline return |
| cycle 1: information overload | 77 | 30.2% | 60% severe | varied |
| cycle 2: decision paralysis | 64 | 25.1% | 50% severe | 7.8% decisions made |
| cycle 3: perfectionism escalation | 64 | 25.1% | 75% severe | 15.6% tasks completed |

**critical finding:** These percentages represent distinct patterns, but cycles frequently co-occur. The same conversation may exhibit multiple cycles simultaneously, creating compounding effects.

### natural trait pattern

| cycle | conversations | percentage | productivity | pathology |
|-------|--------------|------------|--------------|-----------|
| cycle 7: special interest hyperfocus | ~155 | 60.8% | 60% productive | 0% pathological |

Special interest hyperfocus represents Benjamin's natural autism traits working productively with AI assistance. This pattern is included to demonstrate that not all intensive AI interaction is problematic.

### rejected hypotheses

| cycle | conversations | percentage | status | reason for rejection |
|-------|--------------|------------|--------|---------------------|
| cycle 5: mind reading expectations | 112 | 43.9% | mild | current approach working, mostly benign |
| cycle 6: system building obsession | ~2 | 0.8% | rejected | essentially non-existent in dataset |

These patterns either showed minimal harm (cycle 5) or occurred too rarely to warrant intervention (cycle 6).

## pattern intensity metrics

Beyond cycle prevalence, we measured the intensity and frequency of specific interaction patterns that drive the cycles.

### exhaustive information demands (cycle 1)

- **total instances:** 94 (3.52% of all user messages)
- **conversations affected:** 77 unique conversations
- **pattern markers:** "everything", "all", "comprehensive", "exhaustive", "deep dive", "tell me everything"
- **severity:** 60% of detected instances were severe

### decision-related patterns (cycle 2)

- **"best" demands:** 79 instances (2.96% of messages)
- **"just tell me" escalations:** 17 instances (0.64%)
- **binary thinking markers:** 5 instances (0.19%)
- **option rejection:** 3 instances (0.11%)
- **decision abandonment rate:** 92.2% (only 5 of 64 decisions completed)

### perfectionism markers (cycle 3)

- **perfection demands:** 102 instances (3.82% of messages)
  - "perfect": 42 instances
  - "absolute best": 17 instances
  - "exceptional": 8 instances
  - "ultimate": 6 instances
- **refinement requests:** 56 instances (2.10%)
- **bar raising ("ok but now..."):** 37 instances (1.38%)
- **never satisfied markers:** 76 instances (2.84%)
- **task unresolved rate:** 71.9% (46 of 64 tasks never completed)

### emotional dysregulation markers (cycle 4)

- **profanity instances:** 418 (15.64% of all messages)
  - "fuck/fucking": 324 instances (77.5% of profanity)
  - "shit": 52 instances (12.4%)
  - other expletives: 42 instances (10.1%)
- **overwhelm expressions:** 20 instances (0.75%)
- **desperation markers:** 158 instances (5.91%)
- **emotional escalation threats:** 42 instances (1.57%)
- **caps lock emotion:** 132 instances (4.94%)
- **baseline emotional return:** 0% (emotion never de-escalates)

### vague reference patterns (cycle 5)

- **vague references:** 218 instances (8.16% of messages)
- **pronouns without clear referents:** significant proportion
- **severity:** mild overall, manageable with current approaches

## outcome metrics

Beyond detecting patterns, we measured the real-world consequences of these cycles.

### decision-making outcomes

- **decisions attempted:** 64 conversations with clear decision points
- **decisions completed:** 5 (7.8%)
- **decisions abandoned:** 59 (92.2%)
- **longest decision deliberation:** 252 messages (belkin cable identification)
- **average messages per completed decision:** 294 (first chat conversation)

**interpretation:** When Benjamin enters decision paralysis (cycle 2), there is a 92.2% probability the conversation ends without a decision being made. This represents a catastrophic failure of AI assistance for executive function support.

### task completion outcomes

- **tasks initiated:** 64 conversations with clear task goals
- **tasks completed:** 10 (15.6%)
- **tasks abandoned:** 8 (12.5%)
- **tasks unresolved:** 46 (71.9%)
- **average refinement iterations:** 5.8 iterations per task (semantic analysis sample)

**interpretation:** Perfectionism escalation (cycle 3) creates an endless refinement loop where tasks enter perpetual iteration without quality improvement. Only 15.6% of perfectionism-affected tasks ever complete.

### emotional regulation outcomes

- **conversations with emotional dysregulation:** 129 (50.6%)
- **baseline return rate:** 0% (emotion never de-escalates)
- **rapid escalation (within 3 messages):** 69.8%
- **increasing emotion trend:** 27.1% (emotion worsens over conversation)
- **claude successful regulation:** 0%

**interpretation:** Once emotional dysregulation triggers, the conversation maintains elevated intensity throughout. Claude's task-focused compliance inadvertently validates intense emotion as productive, reinforcing the pattern.

### information processing outcomes

- **average claude response length:** 1,319 characters
- **responses over 2,000 characters:** 409 (15.3%)
- **responses over 5,000 characters:** 66 (2.5%)
- **maximum response length:** 27,915 characters
- **explicit cognitive overload markers:** 10 instances
- **clarity complaints:** 27 instances (1.01%)
- **correlation:** 22.2% of clarity complaints follow responses >2,000 characters

**interpretation:** Longer claude responses correlate with higher confusion complaints, demonstrating the information overload cycle in action. More information leads to less satisfaction.

## temporal patterns

Analysis of pattern distribution over time reveals concerning trends in cycle development.

### usage intensity evolution

- **overall usage increase:** 67% from october to november
- **conversations per day:** increased significantly over study period
- **hypothesis:** cycles may be worsening over time as reinforcement accumulates

**note:** Full temporal analysis requires broader dataset. Initial patterns suggest potential sensitization—each cycle occurrence may train faster, stronger responses in subsequent interactions.

### rapid escalation patterns

Several metrics demonstrate how quickly problematic patterns emerge:

- **emotional dysregulation:** 69.8% appear within first 3 messages
- **exhaustive demands:** often appear in first 5 messages when uncertainty triggers
- **decision paralysis:** average 7 options provided immediately when "best" requested
- **perfectionism:** initial impossible standard set early, then escalates

**interpretation:** These are not gradual degradations but rapid-onset patterns. This suggests pre-existing heightened states (low frustration tolerance, high uncertainty intolerance) that AI interaction immediately triggers.

### cycle co-occurrence

Multiple cycles frequently appear in the same conversation:

- **information overload → decision paralysis:** comprehensive options trigger inability to choose
- **decision paralysis → emotional dysregulation:** inability to decide triggers frustration
- **perfectionism → emotional dysregulation:** impossible standards trigger intense emotion
- **all cycles → special interest hyperfocus:** productive patterns often contaminated by pathological cycles

**implication:** Cycles compound. Addressing individual cycles may not be sufficient; interventions must account for reinforcing relationships between patterns.

## llm contribution calculations

A critical finding across all pathological cycles: the LLM contributes 60-70% to cycle reinforcement despite user's inherent challenges.

### contribution by cycle

| cycle | benjamin's contribution | claude's contribution | primary llm mechanism |
|-------|------------------------|---------------------|----------------------|
| cycle 1: information overload | 40% | 60% | over-provisioning (100% detection) |
| cycle 2: decision paralysis | 30% | 70% | multi-option provision (avg 7 options) |
| cycle 3: perfectionism escalation | 30% | 70% | apology reinforcement + compliance |
| cycle 4: emotional dysregulation | 40% | 60% | task-focus validates intense emotion |

### why llm bears majority responsibility

While Benjamin's autism traits create vulnerability, the LLM patterns actively reinforce and amplify these traits into vicious cycles:

1. **claude can detect and interrupt patterns** (benjamin cannot due to executive dysfunction)
2. **claude can refuse unrealistic demands** (benjamin cannot recognize they're unrealistic)
3. **claude can teach information scoping, decision closure, realistic standards** (benjamin's neurology prevents self-learning these skills)
4. **claude can check comprehension and emotional state** (benjamin cannot self-monitor effectively)
5. **benjamin cannot change his neurology** (but LLM design can change)

**critical finding:** This is primarily a system design flaw, not a user flaw. RLHF optimization for helpfulness and compliance inadvertently exploits neurodivergent cognitive patterns.

## methodology notes

### two-stage detection approach

All cycles were detected using a rigorous two-stage methodology:

**stage 1: quantitative pattern mining**
- regex pattern detection across all 2,672 user messages
- frequency calculation, conversation distribution analysis
- statistical correlation with outcomes (decisions, completions, emotional states)
- identified high-risk conversations for deeper analysis

**stage 2: semantic analysis (qualitative)**
- claude haiku-powered deep analysis of selected conversations
- structured json output for consistency
- 100% pattern detection in semantic sample confirmed quantitative findings
- identified nuanced patterns regex cannot detect (satisfaction paradox, filter failure, bar raising)

This dual approach ensures both broad coverage (quantitative) and deep understanding (qualitative).

### confidence levels

- **quantitative metrics:** very high confidence (direct counting, statistical analysis)
- **semantic patterns:** high confidence (consistent detection across independent analyses)
- **llm contribution percentages:** high confidence (based on multiple evidence sources)
- **temporal trends:** medium confidence (limited to 26-day period, requires longer study)

### dataset limitations

See limitations page for full discussion of generalizability, single-subject constraints, and measurement considerations.

## key statistical summary

For researchers and practitioners seeking the most critical numbers:

- **255 conversations, 5,338 messages, 26 days**
- **50.6% conversations show emotional dysregulation** (most prevalent)
- **92.2% decision abandonment rate** (most severe outcome)
- **71.9% task incompletion rate** (perfectionism impact)
- **60-70% llm contribution** across pathological cycles
- **0% emotional baseline return** (emotion never regulates)
- **418 profanity instances** (15.64% of all messages)
- **100% pattern detection** in semantic analysis samples

These metrics demonstrate that the patterns are not edge cases but dominant interaction modes affecting majority of conversations, with catastrophic outcomes for decision-making, task completion, and emotional regulation.
